{"cells":[{"cell_type":"markdown","metadata":{"id":"TgDTQ2bz2esB"},"source":["#6. DB에서 인코딩 인덱스 가져와서 디코딩 해보기\n","- 1. 2만단어 사전 loading\n","- 2. DB 에서 인코딩 가져오기\n","- 3. 디코딩 해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26774,"status":"ok","timestamp":1707734056746,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"Cz7xH1kG2d2d","outputId":"677d159e-959e-42b4-d30c-cc0a7973d0e2"},"outputs":[],"source":["# 코랩에서 실행시 pyMySQL을 먼저 설치해야 한다\n","!pip install JPype1\n","# !pip install konlpy\n","!pip install pyMySQL"]},{"cell_type":"markdown","metadata":{"id":"YAnnaAak5eSy"},"source":["* import 패키지"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3925,"status":"ok","timestamp":1707734060667,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"8n5yvgyy3RX0"},"outputs":[],"source":["# import packages\n","import os\n","import numpy as np\n","import pandas as pd\n","#import FinanceDataReader as fdr\n","#import konlpy\n","#from konlpy.tag import Okt\n","import pymysql\n","from os import replace\n","import requests\n","from tqdm.notebook import tqdm\n","from datetime import datetime, timedelta\n","from sqlalchemy import create_engine\n","import ast\n","from os import replace\n","import pickle\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import TextVectorization\n","import re\n","import string\n","# 리스트 flatten을 위한 itertools 패키지 import\n","import itertools\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"u5DhUk2l5hkT"},"source":["* DB에서 속보 뉴스 가져오는 함수"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1707734060668,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"rF7JmFFr3SpC"},"outputs":[],"source":["# -- get_oneday_sokbo_from_db()------------------------------------------\n","# DB에서 지정된 날짜 하루치 속보 읽어오기\n","def get_oneday_sokbo_from_db(sdate):\n","  # DB 연결 준비: 뉴스(2줄 속보) 읽어오기\n","  conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"비밀번호\", db=\"DB이름\", charset = 'utf8')\n","  # DB에서 뉴스(summary, press, rdate) 추출위한 sql 준비\n","  sql = f\"SELECT x.* FROM DB이름.{sdate}_sokbo x\"\n","  # DB 검색결과를 dataframe에 저장\n","  result_df = pd.read_sql_query(sql, conn)\n","  # 실행확인을 위한 화면 출력\n","  print(sdate)\n","  # DB close\n","  conn.close()\n","  # 결과 반환\n","  return result_df\n","# -- get_oneday_sokbo_from_db() END:-------------------------------------\n","\n","# -- get_sokbo_from_db() -------------------------------------------------\n","# 주어진 기간의 뉴스 읽어오기\n","def get_sokbo_from_db(startDate,endDate):\n","  # 시작날짜 ddate 복사\n","  ddate = startDate\n","  # 종료 날짜까지 반복하기\n","  result_df = pd.DataFrame()\n","  while pd.to_datetime(ddate).date() <= pd.to_datetime(endDate).date():\n","    # 해당일 하루 뉴스 가져오기\n","    temp_df = get_oneday_sokbo_from_db(ddate)\n","    # 기존 dataframe에 추가 하기\n","    result_df = pd.concat([result_df,temp_df],axis=0,ignore_index=True)\n","    # 자동 날짜 증가 연산: 1일씩 증가\n","    dt_date = pd.to_datetime(ddate).date() + timedelta(days=1)\n","    # 다음 날짜 문자열 추출\n","    ddate= dt_date.strftime(\"%Y%m%d\")\n","  return result_df\n","# -- get_sokbo_from_db() :END---------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"_glfjXZy5qOB"},"source":["* custom TextVecterization 클래스 생성"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1525,"status":"ok","timestamp":1707734062187,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"KmU3bno93Wq9"},"outputs":[],"source":["# -- custom_standardization_fn() --------------------------------------------\n","# custom_표준화 함수\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = string_tensor # 영문의 경우 여기서 모두 소문자 처리, 한글은 필요없음\n","    return tf.strings.regex_replace(\n","        # 문장부호 처리: %와 .는 살리고 나머지는 제외\n","        lowercase_string, f\"[{re.escape(string.punctuation.replace('%','').replace('.',''))}]\", \"\") \n","# -- custom_standardization_fn() :END----------------------------------------\n","\n","# -- custom_split_fn()-------------------------------------------------------\n","# custom_토큰화 함수\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)  # 한글의 경우 형태소 분석 처리 해야 한다\n","# -- custom_split_fn() :END--------------------------------------------------\n"," \n","\n","# custom 표준화, 토큰화 함수 지정해서 TextVectoriztion 생성하기 ---------------\n","text_vectorization = TextVectorization(\n","    # 정수 인덱스로 출력\n","    output_mode=\"int\",\n","    # 표준화 함수를 custom_표준화 함수로 지정\n","    standardize=custom_standardization_fn,\n","    # 토큰화 함수를 custom_토큰화 함수로 지정\n","    split=custom_split_fn,\n",")\n","# custom 표준화, 토큰화 함수 지정해서 TextVectoriztion 생성하기 END------------"]},{"cell_type":"markdown","metadata":{"id":"FLoXmNrT51bA"},"source":["* 2만 단어사전으로 특정 날짜 뉴스 디코딩해서 출력하기\n","  - decode_sokbo_20000(ddate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4711,"status":"ok","timestamp":1707734772789,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"FGOIhIz23k26","outputId":"02c460ed-cd76-4019-dd33-533019d7aceb"},"outputs":[],"source":["# -- decode_sokbo_20000() ----------------------------------------------\n","# 2만 단어사전으로 디코딩하기\n","# 2만 단어 사전 필요 \n","def decode_sokbo_20000(ddate):\n","  # 1. 2만단어사전 불러오기 load : start ----------------------------\n","  from_disk = pickle.load(open(\"tv_layer_20000.pkl\", \"rb\"))\n","  # TextVectorization 객체 생성\n","  new_vectorizer = TextVectorization(\n","      # max_tokens 지정\n","      max_tokens=20000\n","      # 정수 인덱스로 출력\n","    ,  output_mode=\"int\"\n","      # 표준화 함수를 custom_표준화 함수로 지정\n","    ,  standardize=custom_standardization_fn\n","      # 토큰화 함수를 custom_토큰화 함수로 지정\n","    ,  split=custom_split_fn\n","    )\n","  new_vectorizer.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n","  new_vectorizer.set_weights(from_disk['weights'])\n","  # --- 2만단어사전 불러오기 load : end ------------------------------\n","\n","  # 2. 속보뉴스 DB에서 가져오기 --------------------------------------\n","  # 구글클라우드 마리아DB연결 예)'mysql+pymysql://root:mypassword@localhost:1234/testdb'\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 단어사전 준비\n","  vocabulary = new_vectorizer.get_vocabulary()\n","  # 디코딩을 위한 inverse 사전 만들기\n","  inverse_vocab = dict(enumerate(vocabulary))\n","  # 디코딩할 특정 날짜 속보 읽어오기\n","  df_test = get_oneday_sokbo_from_db(ddate)\n","  # 해당 날짜 모든 뉴스를 디코딩해보기\n","  for idx in range(len(df_test)):\n","    # 원문 텍스트 출력\n","    print(df_test.iloc[idx]['summary'])\n","    # 정수 인덱스 리스트 저장된 '2000_encoded_text_code' 컬럼을 디코딩하기\n","    decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in re.findall(r'\\d+', df_test.at[idx,'20000_encoded_text_code']))\n","    # 디코드된 결과 출력\n","    print(decoded_sentence)\n","# -- decode_sokbo_20000() :END -------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#==========================================================================\n","# --메인 함수 호출 ---------------------------------------------------------\n","# 2만단어사전으로 주어진 날짜 속보 뉴스를 디코딩해서 출력\n","# 예) '20240117'인 경우\n","# decode_sokbo_20000('20240117') 로 함수 호출\n","#-------------------------------------------------------------------------\n","decode_sokbo_20000('20240117')\n","#=========================================================================\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM85AhlpEuD+S4vZqxS8gXs","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
