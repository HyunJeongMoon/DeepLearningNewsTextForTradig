{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 최종: 매일 실시간 속보 처리하기\n","- 08:28에 실행 되도록 background로 올리기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30393,"status":"ok","timestamp":1709602505363,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"9RX6s6Qw4_aP","outputId":"fae0691b-b583-4ff1-e36d-47af3f9b5b78"},"outputs":[],"source":["# 코랩 실행시 맨 처음 설치 필요\n","# !pip install JPype1\n","# !pip install konlpy\n","# !pip install pyMySQL\n","# !pip install -U finance-datareader\n","# !pip install attention"]},{"cell_type":"markdown","metadata":{"id":"i1ofXr0W9Vxn"},"source":["#* 오늘 속보 처리 함수\n","- 1. 설치 및 konlpy update\n","- 2. 네이버증권 실시간뉴스 속보 읽어오기\n","- 3. konlpy로 토큰화하기\n","- 4. 2만단어 사전으로 TextVectorization 이용해서 인코딩\n","- (5. 2만단어 사전으로 TextVectorization 이용해서 디코딩)\n","- 5-1. today_sokbo_1_step으로 저장\n","- 18개 종목 모델에 넣어서 예측값 얻기\n","- DB에 저장\n","\n","#* /data/model/ 아래에 모델 로드\n","#* 2만단어사전 로드"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":977,"status":"ok","timestamp":1709602744457,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"iAF0rFGu-kfy"},"outputs":[],"source":["# import packages\n","# import packages\n","import os\n","import numpy as np\n","import pandas as pd\n","import FinanceDataReader as fdr\n","import konlpy\n","from konlpy.tag import Okt\n","import pymysql\n","from os import replace\n","import requests\n","from bs4 import BeautifulSoup\n","from tqdm.notebook import tqdm\n","from datetime import datetime\n","from sqlalchemy import create_engine\n","import ast\n","from os import replace\n","import pickle\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import TextVectorization\n","import re\n","import string\n","import itertools\n","import pytz\n","from tensorflow.keras.layers import Dense, Dropout, Activation \\\n","                                  , Embedding, LSTM, Conv1D, MaxPooling1D\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import Model, Sequential,load_model\n","from attention import Attention\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# import END------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10442,"status":"ok","timestamp":1709602599970,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"O8KSwXNRLskL","outputId":"628bedeb-ad8a-49ac-b2c9-4fb7fb7ba300"},"outputs":[],"source":["# --konlpy 커스터마이징  ----------------------------------------------\n","# --------------------------------------------------------------------\n","# Konlpy에 한국거래소 상장종목 전체 종목명과 약명을 새로운 단어로 추가하기\n","# --------------------------------------------------------------------\n","# konlpy 디렉토리로 이동\n","os.chdir('konlpy/설치된/디렉토리/java')\n","# 현재 디렉토리 확인\n","os.getcwd()\n","# 압축 풀 임시 디렉토리 /temp 만들기\n","os.makedirs('./temp')\n","# 임시디렉토리로 이동\n","os.chdir('./temp')\n","# 압축 풀기\n","!jar xvf ../open-korean-text-2.1.0.jar\n","\n","# FinanceDataReader로 한국거래소 상장종목 전체 종목을 가져오기\n","df_krx = fdr.StockListing('KRX')\n","# 종목명만 추출하기\n","name_list = df_krx['Name']\n","# 새로운 단어목록 생성을 위한 data 변수 선언\n","data = ''\n","# 종목명을 한줄씩(\\n)씩 넣어서 목록 만들기\n","for one_name in name_list:\n","  data += one_name+'\\n'\n","# 종목명 약명 새로운 단어로 넣기\n","# DB 연결 준비: 종목명 약어 읽어오기\n","conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"패스워드\", db=\"DB이름\", charset = 'utf8')\n","# DB에서 종목병 약어 추출위한 sql 준비\n","sql = f\"SELECT x.kor_name,x.kor_abb FROM DB이름.테이블이름 x\"\n","# DB 검색결과를 dataframe에 저장\n","name_abb_df = pd.read_sql_query(sql, conn)\n","# 실행확인을 위한 화면 출력\n","print(name_abb_df.head(3))\n","# DB close\n","conn.close()\n","# 종목명 추가하기\n","name_list = name_abb_df['kor_name']\n","# 종목명을 한줄씩(\\n)씩 넣어서 목록 만들기\n","for one_name in name_list:\n","  data += one_name+'\\n'\n","# 종목명 약명 추가하기\n","name_list = name_abb_df['kor_abb']\n","# 종목명 약명을 한줄씩(\\n)씩 넣어서 목록 만들기\n","for one_name in name_list:\n","  data += one_name+'\\n'\n","# konlpy의 company_names.txt 사전으로 저장\n","with open(\"konlpy/설치된/디렉토리/java/temp/org/openkoreantext/processor/util/noun/company_names.txt\", 'w') as f:\n","    f.write(data)\n","# 임시 작업 디렉토리로 이동 확인\n","os.chdir('konlpy/설치된/디렉토리/java/temp')\n","# 다시 압축\n","!jar cvf ../open-korean-text-2.1.0.jar *\n","# 코랩 실행시 Restart session 실행\n","\n","# --konlpy 커스터마이징 END --------------------------------------------"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5456,"status":"ok","timestamp":1709599727369,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"WSAbQ85XL1P-"},"outputs":[],"source":["# !! 코랩 실행시 import 다시하기 !! --------------------------------\n","# import packages\n","import os\n","import numpy as np\n","import pandas as pd\n","import FinanceDataReader as fdr\n","import konlpy\n","from konlpy.tag import Okt\n","import pymysql\n","from os import replace\n","import requests\n","from bs4 import BeautifulSoup\n","from tqdm.notebook import tqdm\n","from datetime import datetime\n","from sqlalchemy import create_engine\n","import ast\n","from os import replace\n","import pickle\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import TextVectorization\n","import re\n","import string\n","import itertools\n","import pytz\n","from tensorflow.keras.layers import Dense, Dropout, Activation \\\n","                                  , Embedding, LSTM, Conv1D, MaxPooling1D\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import Model, Sequential,load_model\n","from attention import Attention\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# import END------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16139,"status":"ok","timestamp":1709599753175,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"FUjw4Izj5SGz","outputId":"292e7240-f5a3-46ba-d32b-e43dfb6a6a67"},"outputs":[],"source":["# --konlpy 커스터마이징 확인 ----------------------------------------------\n","# konlpy 커스터마이징 확인용 코드\n","# 종목명 토크나이즈 확인할 것: 삼성전자 -> '삼성','전자'(X), '삼성전자'(O)\n","# 제대로 안되면 konlpy 커스터마이징 확인\n","import konlpy\n","from konlpy.tag import Okt\n","\n","okt = Okt()\n","print(okt.pos(\"삼성전자 005930 \"))\n","# --konlpy 커스터마이징 확인 End ------------------------------------------"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1211,"status":"ok","timestamp":1709599777108,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"fgVfVTu8-sEz"},"outputs":[],"source":["# ########################################################################\n","# 당일 네이버증권 실시간 속보 뉴스 크롤링 가져오기\n","# ########################################################################\n","\n","# -- ex_news_onePage() ---------------------------------------------------\n","# 한 페이지에 있는 뉴스 가져오기: 페이지당 20개 뉴스 있음\n","# 가져오는 항목: 2줄 요약 summary, 신문사 press, 배포날짜 rdate\n","# BeautifulSoup 객체를 파라미터로 받기\n","def ex_news_onePage(soup):\n","  # 복사본 만들기\n","  soup_1 = soup\n","  # <dd class='articleSummary'> 태그 목록 만들기\n","  ddsum_list = soup_1.find_all('dd', attrs={\"class\": \"articleSummary\"})\n","  # 현재 페이지 전체 뉴스 저장을 위한 news_df 생성\n","  news_df = pd.DataFrame()\n","  # 제일 마지막 페이지에는 <dd class='articleSummary'> 태그 내용이 없음, 뉴스 있는 동안 반복\n","  if len(ddsum_list)>0:\n","    # <dd> 태그 목록에서 하나씩 꺼내기\n","    for ddsum in ddsum_list:\n","      # <dd> 와 </dd> 사이의 텍스트를 추출, 다른 태그 있을시 '^'구분해서 추출, 앞뒤 공백제거\n","      data_string = ddsum.getText('^').strip()\n","      # 추출한 문자열을 '^' 경계로 분리\n","      string_list = data_string.split('^')\n","      # 2줄 요약 news_summary 문자열 추출\n","      news_summary  = string_list[0].strip()\n","      # 신문사 press_name 문자열 추출\n","      press_name    = string_list[1].strip()\n","      # 배포날짜 release_date 문자열 추출\n","      release_date  = string_list[5].strip()\n","      # 추출한 위 3 항목을 DataFrame으로 저장\n","      temp_df = pd.DataFrame(data = [[news_summary,press_name,release_date]], columns=['summary','press','rdate'])\n","      # 현재 페이지 전체 뉴스를 위한 news_df에 추가\n","      news_df = pd.concat([news_df, temp_df], ignore_index=True)\n","  # 현재 페이지 전체 뉴스를 위한 news_df 반환\n","  return news_df\n","# -- ex_news_onePage() :END -----------------------------------------------------\n","\n","# -- ex_news_oneDay() -----------------------------------------------------------\n","# 해당일 뉴스 전체를 가져오기: 페이지 1 부터 끝까지, 1일 10~50여개 페이지(페이지당 20개 뉴스 있음)\n","# 날짜 date 파라미터로 받아서, 네이버증권실시간속보 웹 페이지에 접속\n","# url: f\"https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={날짜}&page={페이지번호}\"\n","# 뉴스 가져올 날짜 date 파라미터로 받기\n","def ex_news_oneDay(date):\n","  # 파라미터 날짜 date 복사\n","  t_target = date\n","  # 페이지번호 초기화\n","  page_num = 0\n","  # 해당일 전체 뉴스 저장을 위한 데이터프레임 df_one_day_news 생성\n","  df_one_day_news = pd.DataFrame()\n","  # while True: 무한 반복문 사용, 날짜별로 뉴스 페이지 갯수가 다르므로 뉴스가 없을 때 반복 종료\n","  while True:\n","    # 페이지번호 1씩 증가\n","    page_num +=1\n","    # 크롤링 할 웹주소 URL, f-string 으로 날짜t_target, 페이지번호page_num 대입\n","    url_1= f\"https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={t_target}&page={page_num}\"\n","    # 웹 request 위한 html 형식 설정\n","    html = requests.get(url_1, headers={\"User-Agent\": \"Mozilla/5.0\"\\\n","    \"(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\\\n","    \"Chrome/110.0.0.0 Safari/537.36\"})\n","    # BeautifulSoup 으로 해당 웹페이지 읽어오기\n","    soup = BeautifulSoup(html.text, \"lxml\")\n","    # 해당 페이지의 뉴스 추출 함수 호출, 한 페이지 뉴스 저장 df_onepagenews\n","    df_onepagenews= ex_news_onePage(soup)\n","    # 해당 페이지에 뉴스가 있으면 당일 전체 뉴스 저장 df_one_day_news 에 추가\n","    if len(df_onepagenews)>0:\n","      df_one_day_news = pd.concat([df_one_day_news,df_onepagenews],ignore_index=True)\n","    # 해당 페이지에 뉴스가 더이상 없으면 반복 종료 break\n","    else:\n","      break\n","  # 해당일 전체 뉴스 df_one_day_news 반환\n","  return df_one_day_news\n","# -- ex_news_oneDay() :END--------------------------------------------------------\n","\n","# -- newsDBsave() ----------------------------------------------------------------\n","# 추출한 일일 뉴스 데이터를 클라우드 MariaDB에 저장\n","# 날짜ddate와 해당일 전체 뉴스 저장한 데이터프레임 news_all 을 파라미터로 받기\n","def newsDBsave(ddate, news_all):\n","  # 테이블 생성 및 연결\n","  # 구글클라우드 마리아DB연결 예)'mysql+pymysql://root:mypassword@localhost:1234/testdb'\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 데이터프레임을 DB로 저장, 날짜 ddate를 테이블 명으로, 이미 있으면 덮어쓰기(replace)\n","  news_all.to_sql(ddate,conn,if_exists='replace')\n","  # DB 커밋\n","  conn.commit()\n","  # DB close\n","  conn.close()\n","# -- newsDBsave() :END-------------------------------------------------------------\n","\n","# -- today_sokbo_DBsave() ---------------------------------------------------------\n","# 당일 속보를 DB에 저장\n","def today_sokbo_DBsave(ddate, news_all):\n","  # 테이블 생성 및 연결\n","  # 구글클라우드 마리아DB연결 예)'mysql+pymysql://root:mypassword@localhost:1234/testdb'\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 데이터프레임을 DB로 저장, 날짜 ddate를 테이블 명으로, 이미 있으면 덮어쓰기(replace)\n","  news_all.to_sql('today_sokbo',conn,if_exists='replace')\n","  # DB 커밋\n","  conn.commit()\n","  # DB close\n","  conn.close()\n","# -- today_sokbo_DBsave() :END--------------------------------------------------------\n","# -- get_today_news_sokbo() ----------------------------------------------------------\n","def get_today_news_sokbo():\n","  # 오늘 현재 시점 날자, GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","  ddate = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y%m%d')\n","  # 해당일 전체 뉴스 가져오기\n","  news_all = ex_news_oneDay(ddate)\n","  # 해당일 전체 뉴스 원본(news) DB에 저장하기\n","  newsDBsave(ddate, news_all)\n","  # 해당일 뉴스 속보(today_sokbo) DB에 저장하기\n","  today_sokbo_DBsave(ddate,news_all)\n","  # 실행중 확인을 위한 날짜 화면 출력\n","  print('today:',ddate)\n","# -- get_today_news_sokbo() :END--------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"buD6SOS9DLw2"},"source":["2. konlpy로 토큰화하기"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1709599779581,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"dPXLoV-PE-d2"},"outputs":[],"source":["# -- tokenize_today_news_summary() ----------------------------------------------------\n","# 오늘 속보 뉴스 summary 를 tokenize 하기\n","# 특정일 날짜: YYYYMMDD ex) 20240105 (문자열)\n","def tokenize_today_news_summary():\n","  # 오늘 현재 시점 날자, GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","  sdate = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y%m%d')\n","  # DB 연결 준비: 뉴스(2줄 속보) 읽어오기\n","  conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"패스워드\", db=\"DB이름\", charset = 'utf8')\n","  # DB에서 뉴스(summary, press, rdate) 추출위한 sql 준비\n","  sql = f\"SELECT x.summary,x.press, x.rdate FROM DB이름.{sdate} x\"\n","  # DB 검색결과를 dataframe에 저장\n","  result_df = pd.read_sql_query(sql, conn)\n","  # 실행확인을 위한 화면 출력\n","  #print(result_df.head(3))\n","  # DB close\n","  conn.close()\n","\n","  # konlpy의 okt 생성\n","  okt=Okt()\n","\n","  # okt로 tokenize해서 형태소 품사 morph 추출하기 (pos 는 okt.pos, 명사는 okt.nouns)\n","  result_df['morphs_tokenized_summary'] = result_df['summary'].apply(okt.morphs)\n","  # DB 저장을 위해 문자열로 변환\n","  result_df['morphs_tokenized_summary'] = result_df['morphs_tokenized_summary'].astype(str)\n","\n","  # okt로 tokenize해서 형태소 pos 추출하기 (품사 전체는 okt.morphs, 명사는 okt.nouns)\n","  result_df['pos_tokenized_summary'] = result_df['summary'].apply(okt.pos)\n","  \n","  # DB 저장을 위해 문자열로 변환\n","  result_df['pos_tokenized_summary'] = result_df['pos_tokenized_summary'].astype(str)\n","\n","  # okt로 tokenize해서 명사 형태소 nouns 추출하기 (품사 전체는 okt.morphs)\n","  result_df['nouns_tokenized_summary'] = result_df['summary'].apply(okt.nouns)\n","  \n","  # DB 저장을 위해 문자열로 변환\n","  result_df['nouns_tokenized_summary'] = result_df['nouns_tokenized_summary'].astype(str)\n","\n","  # pos tokenized 에서 Modifier,Josa,Suffix,Punctuation,Foreigh 제외, 1 자리 단어 제외\n","  result_df['tokenized_summary'] = \"\"\n","  for i in range(len(result_df)):\n","    # 새로운 문자열 위한 리스트\n","    new_str = []\n","    # 튜플 형태로 꺼내면 (단어,품사) 형태이므로 뒤세 품사를 보고 맞는 단어들만 새로운 문자열로 만든다\n","    for (x,y) in ast.literal_eval(result_df['pos_tokenized_summary'][i]):\n","      # 관형사,조사,접두사,문장부호,한자및 기타기호 제외\n","      if (y!='Modifier')&(y!='Josa')&(y!='Suffix')&(y!='Punctuation')&(y!='Foreign'):\n","        # 한글자 짜리 제외\n","        if(len(str(x))>1):\n","          new_str.append(x)\n","    # 실행 확인을 위한 화면 출력\n","    #print(new_str)\n","    # 토크나이즈된 문자열 데이터프레임에 넣기\n","    result_df['tokenized_summary'][i]=str(new_str)\n","\n","  # DB 저장을 위해서 필요한 컬럼 정리\n","  result_df = result_df[['summary','press','rdate','tokenized_summary','pos_tokenized_summary']]\n","  # 실행 확인을 위한 화면 출력\n","  #print(result_df.head(3))\n","\n","  # DB 저장을 위한 연결 준비\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 데이터프레임을 DB로 저장, 날짜 ddate_sokbo를 테이블 명으로, 이미 있으면 덮어쓰기(replace)\n","  result_df.to_sql(sdate+'_sokbo',conn,if_exists='replace')\n","  result_df.to_sql('today_sokbo',conn,if_exists='replace')\n","  # DB 커밋\n","  conn.commit()\n","  # DB close\n","  conn.close()\n","\n","# -- tokenize_today_news_summary() :END---------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"5A7kCZzgHlSn"},"source":["3. 2만단어로 인코딩하기"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709599784594,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"pACMIvI3Hpk-"},"outputs":[],"source":["# -- get_oneday_sokbo_from_db()------------------------------------------\n","# DB에서 지정된 날짜 하루치 속보 읽어오기\n","def get_oneday_sokbo_from_db(sdate):\n","  # DB 연결 준비: 뉴스(2줄 속보) 읽어오기\n","  conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"비밀번호\", db=\"DB이름\", charset = 'utf8')\n","  # DB에서 뉴스(summary, press, rdate) 추출위한 sql 준비\n","  sql = f\"SELECT x.* FROM DB이름.{sdate}_sokbo x\"\n","  # DB 검색결과를 dataframe에 저장\n","  result_df = pd.read_sql_query(sql, conn)\n","  # 실행확인을 위한 화면 출력\n","  print(sdate)\n","  # DB close\n","  conn.close()\n","  # 결과 반환\n","  return result_df\n","# -- get_oneday_sokbo_from_db() END:-------------------------------------\n","\n","# -- get_sokbo_from_db() -------------------------------------------------\n","# 주어진 기간의 뉴스 읽어오기\n","def get_sokbo_from_db(startDate,endDate):\n","  # 시작날짜 ddate 복사\n","  ddate = startDate\n","  # 종료 날짜까지 반복하기\n","  result_df = pd.DataFrame()\n","  while pd.to_datetime(ddate).date() <= pd.to_datetime(endDate).date():\n","    # 해당일 하루 뉴스 가져오기\n","    temp_df = get_oneday_sokbo_from_db(ddate)\n","    # 기존 dataframe에 추가 하기\n","    result_df = pd.concat([result_df,temp_df],axis=0,ignore_index=True)\n","    # 자동 날짜 증가 연산: 1일씩 증가\n","    dt_date = pd.to_datetime(ddate).date() + timedelta(days=1)\n","    # 다음 날짜 문자열 추출\n","    ddate= dt_date.strftime(\"%Y%m%d\")\n","  return result_df\n","# -- get_sokbo_from_db() :END---------------------------------------------\n","\n","# -- custom_standardization_fn() --------------------------------------------\n","# custom_표준화 함수\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = string_tensor # 영문의 경우 여기서 모두 소문자 처리, 한글은 필요없음\n","    return tf.strings.regex_replace(\n","        # 문장부호 처리: %와 .는 살리고 나머지는 제외\n","        lowercase_string, f\"[{re.escape(string.punctuation.replace('%','').replace('.',''))}]\", \"\") \n","# -- custom_standardization_fn() :END----------------------------------------\n","\n","# -- custom_split_fn()-------------------------------------------------------\n","# custom_토큰화 함수\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)  # 한글의 경우 형태소 분석 처리 해야 한다\n","# -- custom_split_fn() :END--------------------------------------------------\n"," \n","\n","# custom 표준화, 토큰화 함수 지정해서 TextVectoriztion 생성하기 ---------------\n","text_vectorization = TextVectorization(\n","    # 정수 인덱스로 출력\n","    output_mode=\"int\",\n","    # 표준화 함수를 custom_표준화 함수로 지정\n","    standardize=custom_standardization_fn,\n","    # 토큰화 함수를 custom_토큰화 함수로 지정\n","    split=custom_split_fn,\n",")\n","# custom 표준화, 토큰화 함수 지정해서 TextVectoriztion 생성하기 END------------"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":493,"status":"ok","timestamp":1709599791255,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"oXmxq3dAIhqf"},"outputs":[],"source":["#  -- encode_save_today_sokbo_20000() --------------------------------------\n","# 2만 단어사전으로 인코딩한 결과 DB에 저장하기\n","def encode_save_today_sokbo_20000():\n","  # 오늘 현재 시점 날자, GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","  sdate = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y%m%d')\n","  \n","  # 1. 2만단어사전 불러오기 load : start --------------\n","  from_disk = pickle.load(open(\"사전경로/tv_layer_20000.pkl\", \"rb\"))\n","\n","  new_vectorizer = TextVectorization(\n","      # max_tokens 지정\n","      max_tokens=20000\n","      # 정수 인덱스로 출력\n","    ,  output_mode=\"int\"\n","      # 표준화 함수를 custom_표준화 함수로 지정\n","    ,  standardize=custom_standardization_fn\n","      # 토큰화 함수를 custom_토큰화 함수로 지정\n","    ,  split=custom_split_fn\n","    )\n","  new_vectorizer.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n","  new_vectorizer.set_weights(from_disk['weights'])\n","  # --- 2만단어사전 불러오기 load : end -----------------\n","\n","  # 2. 속보뉴스 DB에서 가져오기\n","  # 구글클라우드 마리아DB연결 예)'mysql+pymysql://root:mypassword@localhost:1234/testdb'\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 해당 날짜 하루치 속보 DB에서 읽어오기\n","  df_oneday = get_oneday_sokbo_from_db(sdate)\n","  # 위 생성한 백터라이즈를 하루치 속보에 적용 \n","  df_oneday['20000_encoded_text']= list(map(new_vectorizer,df_oneday['tokenized_summary']))\n","  # 하루에 여러 건 뉴스가 있으니 모든 뉴스에 적용 \n","  for i in range(len(df_oneday)):\n","    # 숫자로 인코드된 뉴스를 문자열로 만들어서 DB에 저장\n","    df_oneday.at[i,'20000_encoded_text_code']= str(new_vectorizer(df_oneday.at[i,'tokenized_summary']).numpy())\n","  # 실행 확인을 위한 화면 출력\n","  print(sdate)\n","  # 데이터프레임을 DB로 저장, 날짜 ddate를 테이블 명으로, 이미 있으면 덮어쓰기(replace)\n","  df_oneday.to_sql(sdate+'_sokbo',conn,if_exists='replace',index=False)\n","  # 전망 예측 predict를 위한 working table로 저장\n","  df_oneday.to_sql('today_sokbo_1_step',conn,if_exists='replace',index=False)\n","\n","  # DB 커밋\n","  conn.commit()\n","  # DB close\n","  conn.close()\n","\n","#  -- encode_save_today_sokbo_20000() :END ------------------------------\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1709599799531,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"m-reK7PkSnUR"},"outputs":[],"source":["#=======================================================================\n","# 예측 predict 전에 필요한 당일 뉴스 처리 3 단계 하나로 묶기\n","# 1. 뉴스수집 웹 크롤링, 2. 속보 토큰화, 3. 인코딩\n","#-----------------------------------------------------------------------\n","def today_sokbo_1_step():\n","  get_today_news_sokbo()          # 오늘 속보 웹크롤링\n","  tokenize_today_news_summary()   # 오늘 속보 토큰화\n","  encode_save_today_sokbo_20000() # 오늘 속보 벡터화 인코딩\n","#======================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66562,"status":"ok","timestamp":1709600819893,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"O7G-GirEQqsx","outputId":"1369b01c-00e8-4b65-c098-9e80505ea20c"},"outputs":[],"source":["##############################################################\n","# 예측 predic 실행 전에 이거 먼저 실행 !!!!\n","#=============================================================\n","# step1: 뉴스속보 웹 크롤링부터 벡터 인코딩까지\n","today_sokbo_1_step()\n","##############################################################"]},{"cell_type":"markdown","metadata":{"id":"MZu3Px2RcXsx"},"source":["#* 예측 predict: 학습 모델에 데이터 입력해서 예측값 얻기"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1709606611024,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"LDb9pgPOcUo5"},"outputs":[],"source":["#-------------------------------------------------------------\n","# 1. 데이터셋 만들기\n","# -- get_today_sokbo()---------------------------------------\n","# 오늘 당일 뉴스읽어오기\n","def get_today_sokbo():\n","  # DB 연결 준비: 오늘자 벡터처리된 뉴스(2줄 속보) 읽어오기\n","  conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"패스워드\", db=\"DB이름\", charset = 'utf8')\n","  # DB에서 뉴스(summary, press, rdate) 추출위한 sql 준비\n","  sql = f\"SELECT x.* FROM DB이름.테이블명 x\"\n","  # DB 검색결과를 dataframe에 저장\n","  result_df = pd.read_sql_query(sql, conn)\n","  # 실행확인을 위한 화면 출력\n","  #print(sdate)\n","  # DB close\n","  conn.close()\n","  # 결과 반환\n","  return result_df\n","# -- get_today_sokbo() :END -----------------------------------\n","\n","# -- split_sokbo() --------------------------------------------\n","# 데이터셋 분리: X, y\n","def split_sokbo(df_today_work):\n","  # 컬럼 정리\n","  df_today_outlook = df_today_work[['rdate', 'summary','press']]\n","  # data preparation: 데이터X 분리\n","  X = df_today_work['20000_encoded_text_code']\n","  # 문자열 형식인 데이터X를 리스트로 변환\n","  X= X.apply(lambda x: [int(i) for i in x.strip('[]').split()])\n","  # sequence의 max paddind 길이 설정\n","  sequence_length = 50\n","  # 모델의 padding 길이 맞추기\n","  X = sequence.pad_sequences(X, maxlen= sequence_length)\n","  # predict위한 데이터셋 리턴\n","  return df_today_outlook, X\n","# -- split_sokbo() :END----------------------------------------\n","\n","# -- save_today_outlook()-------------------------------------\n","# 오늘 속보분석 결과 종목별 예측 전망 outlook  DB 저장\n","def save_today_outlook(df_today_work):\n","  # 작업 df 복사\n","  df_today_outlook = df_today_work.copy()\n","  # 구글클라우드 마리아DB연결 예)'mysql+pymysql://root:mypassword@localhost:1234/testdb'\n","  db_connection_path = 'mysql+pymysql://아이디:패스워드@호스트주소:포트번호/DB이름'\n","  db_connection = create_engine(db_connection_path)\n","  # DB 커넥션 생성\n","  conn = db_connection.connect()\n","  # 실행중 확인을 위한 화면 출력\n","  print('-*')\n","  # 종합 상승/보합/하락 전망 예측 내고 DB 저장\n","  # 종합 전망 저장 위한 df 생성\n","  df_today_outlook_signal= pd.DataFrame()\n","  # '종목명_outlook' 컬럼명을 인덱스용도로 쓸 컬럼의 값으로 넣기\n","  df_today_outlook_signal['code_outlook'] = df_today_outlook.columns[3:].values\n","  # 18개 종목 예측 전망 처리\n","  for i in range(3,21):\n","    # 1개 종목 처리용 df 생성\n","    df_temp = pd.DataFrame()\n","    # 실행 확인을 위한 화면 출력\n","    print('컬럼명: ', df_today_outlook.columns[i])\n","    # 상승2/보합0/하락1 갯수 세기\n","    df_vc = df_today_outlook.iloc[:,i].value_counts()\n","    # 있는 카테고리를 set으로 변환\n","    set_vc = set(df_vc.index)\n","    # 전체 카테고리를 set로 준비\n","    set_cat = set([0,1,2])\n","    # 없는 카테고리를 set으로 구하기\n","    set_result = set_cat - set_vc\n","    # 없는 카테고리 값을 0으로 채우기\n","    if set_result:\n","      for inum in set_result:\n","        df_vc[inum] =0\n","    # 실행 확인을 위한 화면 출력\n","    print(\"df_vc:\",df_vc)\n","    # 해당 종목의 하락 0 갯수 넣기\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'outlook_0'] = df_vc[0]\n","    # 해당 종목의 보합 1 갯수 넣기\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'outlook_1'] = df_vc[1]\n","    # 해당 종목의 하락 2 상승 넣기\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'outlook_2'] = df_vc[2]\n","    # 종합 전망: 최빈값 넣기\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'most_values'] = df_vc.idxmax()\n","    # 종합 전망 갯수: 최대 갯수 넣기\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'most_count'] = df_vc.max()\n","    # 시간 컬럼 넣기, , GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","    df_today_outlook_signal.loc[df_today_outlook_signal['code_outlook']==df_today_outlook.columns[i], 'curent_time'] = datetime.now(pytz.timezone('Asia/Seoul')).strftime(\"%Y%m%d%H%M\")\n","\n","\n","  # 데이터프레임을 DB로 저장, 날짜 ddate 붙인 백업테이블, 화면 출력 위한 오늘테이블 2개로 저장, 이미 있으면 덮어쓰기(replace)\n","  # 실행확인용 화면출력\n","  print('saving DB 1')\n","  # 백업 테이블 저장,, GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","  df_today_outlook.to_sql('today_sokbo_outlook_'+datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y%m%d'),conn,if_exists='replace',index=False)\n","\n","  # 실행확인용 화면출력\n","  print('saving DB 2')\n","  # today_sokbo_outlook 테이블 저장\n","  df_today_outlook.to_sql('today_sokbo_outlook',conn,if_exists='replace',index=False)\n","\n","  # 실행확인용 화면출력\n","  print('saving DB 3')\n","  # 종합 전망 테이블 백업 저장,, GCP locale이 한국이 아닐 수도 있으니 timezone 맞춘다\n","  df_today_outlook_signal.to_sql('today_sokbo_outlook_signal_'+datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y%m%d'),conn,if_exists='replace',index=False)\n","\n","  # 실행확인용 화면출력\n","  print('saving DB 4')\n","  # 종합 전망 테이블 저장\n","  df_today_outlook_signal.to_sql('today_sokbo_outlook_signal',conn,if_exists='replace',index=False)\n","  print('-- Finish')\n","  # DB 커밋\n","  conn.commit()\n","  # DB close\n","  conn.close()\n","# -- save_today_outlook() :END -----------------------------------\n","\n","# --get_top_18() -------------------------------------------------\n","# 18종목 종목이름과 코드 가져오기\n","def get_top_18():\n","  # DB 연결 준비\n","  conn = pymysql.connect(host= '호스트주소', port = 포트번호, user=\"아이디\", password=\"패스워드\", db=\"DB이름\", charset = 'utf8')\n","  # sql 쿼리 준비\n","  sql = f\"SELECT x.* FROM 테이블이름 x\"\n","  # DB 검색결과를 dataframe에 저장\n","  df_top_18 = pd.read_sql_query(sql, conn)\n","  # DB close\n","  conn.close()\n","  # 쿼리 결과 반환\n","  return df_top_18\n","#-- get_top_18(): End ---------------------------------------------\n","\n","# 1. 데이터셋 만들기 : END-------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20362,"status":"ok","timestamp":1709602775257,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"FBR8tNEjQqp5","outputId":"30ed074b-2832-4c8f-8f3a-1bbb0822c9af"},"outputs":[],"source":["#------------------------------------------------------------------\n","# 2. 모델 load, 예측값 얻기\n","#------------------------------------------------------------------\n","# 예측위한 X dataset 분리\n","df_today_outlook, X = split_sokbo(get_today_sokbo())\n","\n","# 실행 확인을 위한 화면 출력\n","print(X[0])\n","# 실행 확인을 위한 화면 출력\n","print('** 예측 모델 Load **')\n","\n","# ### 한 종목씩 개별 예측, 루프 X #####\n","\n","#1번종목------------------------------------------------------------------------------\n","stock_code = '405100'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#2-----------------------------------------------------------------------------------\n","stock_code = '270660'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#3-----------------------------------------------------------------------------------\n","stock_code = '196170'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#4----------------------------------------------------------------------------------\n","stock_code = '348370'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#5-----------------------------------------------------------------------------------\n","stock_code = '092600'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#6-----------------------------------------------------------------------------------\n","stock_code = '006920'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#7-----------------------------------------------------------------------------------\n","stock_code = '011420'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#8----------------------------------------------------------------------------------\n","stock_code = '245620'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#9----------------------------------------------------------------------------------\n","stock_code = '237820'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#10---------------------------------------------------------------------------------\n","stock_code = '066790'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#11-----------------------------------------------------------------------------------\n","stock_code = '394280'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#12----------------------------------------------------------------------------------\n","stock_code = '051370'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#13---------------------------------------------------------------------------------\n","stock_code = '041190'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#14----------------------------------------------------------------------------------\n","stock_code = '457190'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#15---------------------------------------------------------------------------------\n","stock_code = '005930'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#16----------------------------------------------------------------------------------\n","stock_code = '000660'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#17---------------------------------------------------------------------------------\n","stock_code = '123570'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","#18----------------------------------------------------------------------------------\n","stock_code = '004380'\n","# 모델이름 지정\n","model_name = f'LSTM_sokbo_{stock_code}_b128_e200_32.hdf5'\n","# 예측 모델 load\n","model = load_model(filepath=f'모델경로/{model_name}')\n","# 예측 전망(0/1/2) 얻기\n","stock_outlook = np.argmax(model.predict(X), axis=1)\n","# DB 저장위한 df에 넣기\n","df_today_outlook[stock_code+'_outlook'] = stock_outlook\n","#-----------------------------------------------------------------------------------\n","\n","# 2. 모델 load, 예측값 얻기 :END------------------------------------------------------\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32737,"status":"ok","timestamp":1709606653158,"user":{"displayName":"hyun","userId":"14298231370728061195"},"user_tz":-540},"id":"o9j40hTC36AH","outputId":"271e1c57-7fae-4b21-faa5-fb234648f383"},"outputs":[],"source":["##############################################################\n","# step2: 최종 메인 - 예측 전망 DB 저장 \n","#-------------------------------------------------------------\n","save_today_outlook(df_today_outlook)\n","#-------------------------------------------------------------\n","##############################################################"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNMeY+SwV0Nn+NIzIjX6Tj0","gpuType":"T4","provenance":[{"file_id":"1sVvBAX71H1Q6tKTV-UCNjWyFHv4t4fFk","timestamp":1709082290430}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
